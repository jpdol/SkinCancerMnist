{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Sequential,Input,Model,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, GaussianNoise\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\7\\Anaconda3\\envs\\tg-gpu-ptchd\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", name=\"prediction\", units=2)`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\7\\Anaconda3\\envs\\tg-gpu-ptchd\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "vgg16 = VGG16(weights='imagenet')\n",
    "x = vgg16.get_layer('fc1').output\n",
    "x = BatchNormalization(name = 'BatchNormalization_0')(x)\n",
    "x = Dropout(0.3, name = 'dropout0')(x)\n",
    "x = vgg16.get_layer('fc2')(x)\n",
    "x = BatchNormalization(name = 'BatchNormalization_1')(x)\n",
    "x = Dropout(0.3, name = 'dropout1')(x)\n",
    "prediction = Dense(output_dim=2, activation='softmax', name='prediction')(x)\n",
    "model = Model(input=vgg16.input, output=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow0_col1 {\n",
       "            background-color:  red;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow1_col1 {\n",
       "            background-color:  red;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow2_col1 {\n",
       "            background-color:  red;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow3_col1 {\n",
       "            background-color:  red;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow4_col1 {\n",
       "            background-color:  red;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow5_col1 {\n",
       "            background-color:  red;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow6_col1 {\n",
       "            background-color:  red;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow7_col1 {\n",
       "            background-color:  red;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow8_col1 {\n",
       "            background-color:  red;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow9_col1 {\n",
       "            background-color:  red;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow10_col1 {\n",
       "            background-color:  red;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow11_col1 {\n",
       "            background-color:  red;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow12_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow13_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow14_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow15_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow16_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow17_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow18_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow19_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow20_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow21_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow22_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow23_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow24_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow25_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow26_col1 {\n",
       "            background-color:  yellow;\n",
       "        }</style>  \n",
       "<table id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2e\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >layer</th> \n",
       "        <th class=\"col_heading level0 col1\" >trainable</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row0\" class=\"row_heading level0 row0\" >0</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow0_col0\" class=\"data row0 col0\" >input_1</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow0_col1\" class=\"data row0 col1\" >False</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row1\" class=\"row_heading level0 row1\" >1</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow1_col0\" class=\"data row1 col0\" >block1_conv1</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow1_col1\" class=\"data row1 col1\" >False</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row2\" class=\"row_heading level0 row2\" >2</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow2_col0\" class=\"data row2 col0\" >block1_conv2</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow2_col1\" class=\"data row2 col1\" >False</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row3\" class=\"row_heading level0 row3\" >3</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow3_col0\" class=\"data row3 col0\" >block1_pool</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow3_col1\" class=\"data row3 col1\" >False</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row4\" class=\"row_heading level0 row4\" >4</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow4_col0\" class=\"data row4 col0\" >block2_conv1</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow4_col1\" class=\"data row4 col1\" >False</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row5\" class=\"row_heading level0 row5\" >5</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow5_col0\" class=\"data row5 col0\" >block2_conv2</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow5_col1\" class=\"data row5 col1\" >False</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row6\" class=\"row_heading level0 row6\" >6</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow6_col0\" class=\"data row6 col0\" >block2_pool</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow6_col1\" class=\"data row6 col1\" >False</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row7\" class=\"row_heading level0 row7\" >7</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow7_col0\" class=\"data row7 col0\" >block3_conv1</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow7_col1\" class=\"data row7 col1\" >False</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row8\" class=\"row_heading level0 row8\" >8</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow8_col0\" class=\"data row8 col0\" >block3_conv2</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow8_col1\" class=\"data row8 col1\" >False</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row9\" class=\"row_heading level0 row9\" >9</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow9_col0\" class=\"data row9 col0\" >block3_conv3</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow9_col1\" class=\"data row9 col1\" >False</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row10\" class=\"row_heading level0 row10\" >10</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow10_col0\" class=\"data row10 col0\" >block3_pool</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow10_col1\" class=\"data row10 col1\" >False</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row11\" class=\"row_heading level0 row11\" >11</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow11_col0\" class=\"data row11 col0\" >block4_conv1</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow11_col1\" class=\"data row11 col1\" >False</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row12\" class=\"row_heading level0 row12\" >12</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow12_col0\" class=\"data row12 col0\" >block4_conv2</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow12_col1\" class=\"data row12 col1\" >True</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row13\" class=\"row_heading level0 row13\" >13</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow13_col0\" class=\"data row13 col0\" >block4_conv3</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow13_col1\" class=\"data row13 col1\" >True</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row14\" class=\"row_heading level0 row14\" >14</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow14_col0\" class=\"data row14 col0\" >block4_pool</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow14_col1\" class=\"data row14 col1\" >True</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row15\" class=\"row_heading level0 row15\" >15</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow15_col0\" class=\"data row15 col0\" >block5_conv1</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow15_col1\" class=\"data row15 col1\" >True</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row16\" class=\"row_heading level0 row16\" >16</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow16_col0\" class=\"data row16 col0\" >block5_conv2</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow16_col1\" class=\"data row16 col1\" >True</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row17\" class=\"row_heading level0 row17\" >17</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow17_col0\" class=\"data row17 col0\" >block5_conv3</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow17_col1\" class=\"data row17 col1\" >True</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row18\" class=\"row_heading level0 row18\" >18</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow18_col0\" class=\"data row18 col0\" >block5_pool</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow18_col1\" class=\"data row18 col1\" >True</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row19\" class=\"row_heading level0 row19\" >19</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow19_col0\" class=\"data row19 col0\" >flatten</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow19_col1\" class=\"data row19 col1\" >True</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row20\" class=\"row_heading level0 row20\" >20</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow20_col0\" class=\"data row20 col0\" >fc1</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow20_col1\" class=\"data row20 col1\" >True</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row21\" class=\"row_heading level0 row21\" >21</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow21_col0\" class=\"data row21 col0\" >BatchNormalization_0</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow21_col1\" class=\"data row21 col1\" >True</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row22\" class=\"row_heading level0 row22\" >22</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow22_col0\" class=\"data row22 col0\" >dropout0</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow22_col1\" class=\"data row22 col1\" >True</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row23\" class=\"row_heading level0 row23\" >23</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow23_col0\" class=\"data row23 col0\" >fc2</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow23_col1\" class=\"data row23 col1\" >True</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row24\" class=\"row_heading level0 row24\" >24</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow24_col0\" class=\"data row24 col0\" >BatchNormalization_1</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow24_col1\" class=\"data row24 col1\" >True</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row25\" class=\"row_heading level0 row25\" >25</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow25_col0\" class=\"data row25 col0\" >dropout1</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow25_col1\" class=\"data row25 col1\" >True</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2elevel0_row26\" class=\"row_heading level0 row26\" >26</th> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow26_col0\" class=\"data row26 col0\" >prediction</td> \n",
       "        <td id=\"T_f3abce12_f722_11e8_9bd5_1c1b0dc0dc2erow26_col1\" class=\"data row26 col1\" >True</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x222ac7ab898>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for layer in model.layers:\n",
    "    if layer.name in ['fc1', 'fc2', 'prediction', 'dropout0', 'dropout1', 'flatten',\n",
    "                      'block5_pool', 'block5_conv3', 'block5_conv2', 'block5_conv1',\n",
    "                      'block4_pool', 'block4_conv3', 'block4_conv2',\n",
    "                      'BatchNormalization_0', 'BatchNormalization_1']:\n",
    "        continue\n",
    "    layer.trainable = False\n",
    "\n",
    "df = pd.DataFrame(([layer.name, layer.trainable] for layer in model.layers), columns=['layer', 'trainable'])\n",
    "df.style.applymap(lambda trainable: f'background-color: {\"yellow\" if trainable else \"red\"}', subset=['trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "sgd = SGD(lr=1e-4, momentum=0.9)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1732 images belonging to 2 classes.\n",
      "Found 447 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "\n",
    "def preprocess_input_vgg(x):\n",
    "    \"\"\"Wrapper around keras.applications.vgg16.preprocess_input()\n",
    "    to make it compatible for use with keras.preprocessing.image.ImageDataGenerator's\n",
    "    `preprocessing_function` argument.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : a numpy 3darray (a single image to be preprocessed)\n",
    "    \n",
    "    Note we cannot pass keras.applications.vgg16.preprocess_input()\n",
    "    directly to to keras.preprocessing.image.ImageDataGenerator's\n",
    "    `preprocessing_function` argument because the former expects a\n",
    "    4D tensor whereas the latter expects a 3D tensor. Hence the\n",
    "    existence of this wrapper.\n",
    "    \n",
    "    Returns a numpy 3darray (the preprocessed image).\n",
    "    \n",
    "    \"\"\"\n",
    "    from keras.applications.vgg16 import preprocess_input\n",
    "    X = np.expand_dims(x, axis=0)\n",
    "    X = preprocess_input(X)\n",
    "    return X[0]\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory(directory=r'C:\\Users\\7\\Desktop\\Desktop\\dataset\\cancer mnist\\binary dataset\\mel\\train',\n",
    "                                                    target_size=[224,224],\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg)\n",
    "validation_generator = validation_datagen.flow_from_directory(directory=r'C:\\Users\\7\\Desktop\\Desktop\\dataset\\cancer mnist\\binary dataset\\mel\\test',\n",
    "                                                              target_size=[224,224],\n",
    "                                                              batch_size=32,\n",
    "                                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\7\\Anaconda3\\envs\\tg-gpu-ptchd\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"\n",
      "C:\\Users\\7\\Anaconda3\\envs\\tg-gpu-ptchd\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=64, validation_data=<keras_pre..., validation_steps=32, epochs=10)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "64/64 [==============================] - 181s 3s/step - loss: 0.1874 - acc: 0.9267 - val_loss: 0.7061 - val_acc: 0.8102\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 42s 650ms/step - loss: 0.2055 - acc: 0.9278 - val_loss: 0.5694 - val_acc: 0.8219\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 42s 655ms/step - loss: 0.1911 - acc: 0.9287 - val_loss: 0.4047 - val_acc: 0.8493\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 43s 664ms/step - loss: 0.1701 - acc: 0.9331 - val_loss: 0.6154 - val_acc: 0.8335\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 41s 648ms/step - loss: 0.1962 - acc: 0.9277 - val_loss: 0.4826 - val_acc: 0.8337\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 43s 676ms/step - loss: 0.1833 - acc: 0.9292 - val_loss: 0.8580 - val_acc: 0.8023\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 48s 753ms/step - loss: 0.1914 - acc: 0.9322 - val_loss: 0.5289 - val_acc: 0.8394\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 40s 626ms/step - loss: 0.1672 - acc: 0.9394 - val_loss: 1.0082 - val_acc: 0.7730\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 42s 657ms/step - loss: 0.1478 - acc: 0.9463 - val_loss: 0.5646 - val_acc: 0.8239\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 42s 654ms/step - loss: 0.2023 - acc: 0.9283 - val_loss: 1.1074 - val_acc: 0.7652\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=64,\n",
    "                    nb_epoch=10,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 447 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "predict_gen = validation_datagen.flow_from_directory(directory=r'C:\\Users\\7\\Desktop\\Desktop\\dataset\\cancer mnist\\binary dataset\\mel\\test',\n",
    "                                                              target_size=[224, 224],\n",
    "                                                              batch_size=447,\n",
    "                                                              class_mode='categorical')\n",
    "\n",
    "X_val_sample, res = next(predict_gen)\n",
    "y_pred = model.predict(X_val_sample)\n",
    "\n",
    "CM = []\n",
    "for i in range(2):\n",
    "    CM.append([0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[216, 7]\n",
      "[99, 125]\n",
      "14/14 [==============================] - 4s 270ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1240309951222716, 0.762863532808803]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y in zip(res, y_pred):\n",
    "    CM[np.argmax(x)][np.argmax(y)] = CM[np.argmax(x)][np.argmax(y)] + 1\n",
    "    #s = pd.Series({'Afr': y[0], 'Asi': y[1], 'Brc':y[2], 'Ind':y[3], 'Lat':y[4]})\n",
    "    #axes = s.plot(kind='bar')\n",
    "    #axes.set_xlabel('Class')\n",
    "    #axes.set_ylabel('Probability')\n",
    "    #axes.set_ylim([0, 1])\n",
    "    #plt.show()\n",
    "for line in CM:\n",
    "    print(line)\n",
    "    #img = array_to_img(x)\n",
    "    #print(res[index])\n",
    "    #display(i\n",
    "model.evaluate_generator(validation_generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "onedtrue = []\n",
    "onedpred = []\n",
    "for true, pred in zip(res, y_pred):\n",
    "    onedtrue.append(np.argmax(true))\n",
    "    onedpred.append(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         mel       0.69      0.97      0.80       223\n",
      "     mel-non       0.95      0.56      0.70       224\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       447\n",
      "   macro avg       0.82      0.76      0.75       447\n",
      "weighted avg       0.82      0.76      0.75       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['mel', 'mel-non']\n",
    "print(classification_report(onedtrue, onedpred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mel-8031-4-epc.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Sequential,Input,Model,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, GaussianNoise\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 541 images belonging to 2 classes.\n",
      "Found 136 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "\n",
    "def preprocess_input_vgg(x):\n",
    "    \"\"\"Wrapper around keras.applications.vgg16.preprocess_input()\n",
    "    to make it compatible for use with keras.preprocessing.image.ImageDataGenerator's\n",
    "    `preprocessing_function` argument.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : a numpy 3darray (a single image to be preprocessed)\n",
    "    \n",
    "    Note we cannot pass keras.applications.vgg16.preprocess_input()\n",
    "    directly to to keras.preprocessing.image.ImageDataGenerator's\n",
    "    `preprocessing_function` argument because the former expects a\n",
    "    4D tensor whereas the latter expects a 3D tensor. Hence the\n",
    "    existence of this wrapper.\n",
    "    \n",
    "    Returns a numpy 3darray (the preprocessed image).\n",
    "    \n",
    "    \"\"\"\n",
    "    from keras.applications.vgg16 import preprocess_input\n",
    "    X = np.expand_dims(x, axis=0)\n",
    "    X = preprocess_input(X)\n",
    "    return X[0]\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory(directory=r'C:\\Users\\7\\Desktop\\Desktop\\dataset\\cancer mnist\\binary dataset\\akiec\\train',\n",
    "                                                    target_size=[140, 140],\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg)\n",
    "validation_generator = validation_datagen.flow_from_directory(directory=r'C:\\Users\\7\\Desktop\\Desktop\\dataset\\cancer mnist\\binary dataset\\akiec\\test',\n",
    "                                                              target_size=[140, 140],\n",
    "                                                              batch_size=32,\n",
    "                                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(r'C:\\Users\\7\\Desktop\\Desktop\\dataset\\cancer mnist\\ensemble\\mel-8031-4-epc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for k in range(506):\n",
    "    predictions.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 506 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predict_gen = validation_datagen.flow_from_directory(directory=r'C:\\Users\\7\\Desktop\\Desktop\\dataset\\cancer mnist\\unbalanced\\test',\n",
    "                                                              target_size=[224,224],\n",
    "                                                              batch_size=506,\n",
    "                                                              shuffle = False,\n",
    "                                                              class_mode='categorical')\n",
    "\n",
    "X_val_sample, res = next(predict_gen)\n",
    "y_pred = model.predict(X_val_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,y in enumerate(y_pred):\n",
    "    predictions[index].append(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "onedtrue = []\n",
    "onedpred = []\n",
    "for true, pred in zip(res, y_pred):\n",
    "    onedtrue.append(np.argmax(true))\n",
    "    onedpred.append(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 28,  38,   0,   0,   0,   0],\n",
       "       [ 32,  71,   0,   0,   0,   0],\n",
       "       [ 64,  39,   0,   0,   0,   0],\n",
       "       [103,   0,   0,   0,   0,   0],\n",
       "       [ 29,  74,   0,   0,   0,   0],\n",
       "       [  2,  26,   0,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(onedtrue, onedpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"pred_mel.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(predictions, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-INCPT-PATCHED",
   "language": "python",
   "name": "tf-gpu-ptc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
